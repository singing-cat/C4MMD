nohup: ignoring input
/usr/local/miniconda3/envs/mllm/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:290: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.set_default_device, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/miniconda3/envs/mllm/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:245: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/miniconda3/envs/mllm/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/usr/local/miniconda3/envs/mllm/lib/python3.10/site-packages/timm/models/hub.py:4: FutureWarning: Importing from timm.models.hub is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
/usr/local/miniconda3/envs/mllm/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:568: UserWarning: `pad_token_id` should be positive but got -1. This will cause errors when batch generating, if there is padding. Please set `pad_token_id` explicitly as `model.generation_config.pad_token_id=PAD_TOKEN_ID` to avoid errors in generation
  warnings.warn(
InternLMForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
<frozen importlib._bootstrap>:671: ImportWarning: TBEMetaPathLoader.exec_module() not found; falling back to load_module()
<frozen importlib._bootstrap>:914: ImportWarning: TEMetaPathFinder.find_spec() not found; falling back to find_module()
<frozen importlib._bootstrap>:671: ImportWarning: TBEMetaPathLoader.exec_module() not found; falling back to load_module()
Please following docs/install.md to install rotary_emb if you want to do fine-tuning
Init VIT ... Done
Init Perceive Sampler ... Done
Init InternLM ... Done
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.36it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.67it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.98it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.68it/s]
  0%|          | 0/6023 [00:00<?, ?it/s]<frozen importlib._bootstrap>:914: ImportWarning: TEMetaPathFinder.find_spec() not found; falling back to find_module()
<frozen importlib._bootstrap>:671: ImportWarning: TEMetaPathLoader.exec_module() not found; falling back to load_module()
/usr/local/miniconda3/envs/mllm/lib/python3.10/site-packages/torch_npu/utils/storage.py:38: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if self.device.type != 'cpu':
/usr/local/miniconda3/envs/mllm/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:568: UserWarning: `pad_token_id` should be positive but got -1. This will cause errors when batch generating, if there is padding. Please set `pad_token_id` explicitly as `model.generation_config.pad_token_id=PAD_TOKEN_ID` to avoid errors in generation
  warnings.warn(
  0%|          | 1/6023 [00:32<54:02:36, 32.31s/it]  0%|          | 2/6023 [01:07<57:12:03, 34.20s/it]  0%|          | 3/6023 [01:34<51:33:04, 30.83s/it]  0%|          | 4/6023 [02:07<53:11:55, 31.82s/it]  0%|          | 5/6023 [02:44<56:08:23, 33.58s/it]  0%|          | 6/6023 [03:39<68:20:40, 40.89s/it]  0%|          | 7/6023 [04:10<62:57:56, 37.68s/it]  0%|          | 8/6023 [05:48<94:44:13, 56.70s/it]  0%|          | 9/6023 [06:19<81:19:14, 48.68s/it]  0%|          | 10/6023 [07:01<77:59:49, 46.70s/it]  0%|          | 11/6023 [07:37<72:24:52, 43.36s/it]  0%|          | 12/6023 [07:57<60:34:02, 36.27s/it]  0%|          | 13/6023 [08:40<64:10:38, 38.44s/it]  0%|          | 14/6023 [09:16<62:30:56, 37.45s/it]  0%|          | 15/6023 [09:46<59:05:16, 35.41s/it]/root/.cache/huggingface/modules/transformers_modules/internlm/internlm-xcomposer-7b/e966f76c4294e825d97553260be065eca6a10c22/modeling_InternLM_XComposer.py:159: ResourceWarning: unclosed file <_io.BufferedReader name='/data/sy/C4MMD/data/image/Chinese/Image- (5268).jpg'>
  image = Image.open(image).convert("RGB")
  0%|          | 16/6023 [11:05<80:44:00, 48.38s/it]  0%|          | 17/6023 [12:38<103:03:29, 61.77s/it]  0%|          | 18/6023 [12:58<82:08:32, 49.24s/it]   0%|          | 19/6023 [14:13<95:07:55, 57.04s/it]  0%|          | 20/6023 [14:36<78:15:53, 46.94s/it]  0%|          | 21/6023 [16:18<105:39:54, 63.38s/it]  0%|          | 22/6023 [18:03<126:41:07, 76.00s/it]  0%|          | 23/6023 [18:39<106:15:23, 63.75s/it]  0%|          | 24/6023 [19:10<90:07:09, 54.08s/it]   0%|          | 25/6023 [19:36<75:46:23, 45.48s/it]  0%|          | 26/6023 [20:37<83:44:22, 50.27s/it]  0%|          | 27/6023 [22:22<110:57:11, 66.62s/it]  0%|          | 28/6023 [24:01<127:09:19, 76.36s/it]  0%|          | 29/6023 [24:37<106:56:12, 64.23s/it]  0%|          | 30/6023 [25:14<93:36:22, 56.23s/it]   1%|          | 31/6023 [25:56<86:30:04, 51.97s/it]  1%|          | 32/6023 [26:44<84:05:37, 50.53s/it]  1%|          | 33/6023 [27:28<80:56:09, 48.64s/it]  1%|          | 34/6023 [27:52<68:36:54, 41.24s/it]  1%|          | 35/6023 [28:26<64:54:08, 39.02s/it]  1%|          | 36/6023 [29:07<66:06:25, 39.75s/it]  1%|          | 37/6023 [30:44<94:28:34, 56.82s/it]  1%|          | 38/6023 [31:34<91:23:05, 54.97s/it]  1%|          | 39/6023 [32:26<89:52:16, 54.07s/it]  1%|          | 40/6023 [34:09<113:51:24, 68.51s/it]  1%|          | 41/6023 [34:45<97:40:03, 58.78s/it]   1%|          | 42/6023 [35:19<85:35:03, 51.51s/it]  1%|          | 43/6023 [36:18<89:07:46, 53.66s/it]  1%|          | 44/6023 [37:04<85:21:36, 51.40s/it]  1%|          | 45/6023 [38:52<113:45:11, 68.50s/it]  1%|          | 46/6023 [39:39<102:40:35, 61.84s/it]  1%|          | 47/6023 [40:24<94:16:51, 56.80s/it]   1%|          | 48/6023 [40:49<78:47:46, 47.48s/it]  1%|          | 49/6023 [42:27<103:51:10, 62.58s/it]  1%|          | 50/6023 [42:53<85:36:40, 51.60s/it]   1%|          | 51/6023 [43:48<87:06:54, 52.51s/it]  1%|          | 52/6023 [44:10<71:47:29, 43.28s/it]  1%|          | 53/6023 [44:48<69:24:00, 41.85s/it]  1%|          | 54/6023 [46:27<97:31:45, 58.82s/it]  1%|          | 55/6023 [46:55<82:23:14, 49.70s/it]  1%|          | 56/6023 [47:37<78:25:02, 47.31s/it]  1%|          | 57/6023 [48:09<71:12:02, 42.96s/it]  1%|          | 58/6023 [48:33<61:28:28, 37.10s/it]  1%|          | 59/6023 [49:54<83:17:39, 50.28s/it]  1%|          | 60/6023 [50:12<67:30:18, 40.75s/it]  1%|          | 61/6023 [50:42<62:00:17, 37.44s/it]  1%|          | 62/6023 [51:30<67:11:16, 40.58s/it]  1%|          | 63/6023 [52:02<62:42:06, 37.87s/it]  1%|          | 64/6023 [52:43<64:36:31, 39.03s/it]  1%|          | 65/6023 [53:08<57:29:38, 34.74s/it]  1%|          | 66/6023 [54:44<88:01:08, 53.19s/it]  1%|          | 67/6023 [55:04<71:19:43, 43.11s/it]  1%|          | 68/6023 [55:20<57:48:41, 34.95s/it]  1%|          | 69/6023 [56:05<62:38:16, 37.87s/it]  1%|          | 70/6023 [56:44<63:20:32, 38.31s/it]  1%|          | 71/6023 [57:25<64:40:41, 39.12s/it]  1%|          | 72/6023 [57:59<61:57:44, 37.48s/it]  1%|          | 73/6023 [59:50<98:39:55, 59.70s/it]  1%|          | 74/6023 [1:00:48<97:53:45, 59.24s/it]  1%|          | 75/6023 [1:01:27<87:44:44, 53.11s/it]  1%|▏         | 76/6023 [1:02:12<83:45:51, 50.71s/it]  1%|▏         | 77/6023 [1:03:06<85:26:13, 51.73s/it]  1%|▏         | 78/6023 [1:03:39<76:01:48, 46.04s/it]  1%|▏         | 79/6023 [1:07:16<160:28:41, 97.19s/it]  1%|▏         | 80/6023 [1:09:03<165:21:42, 100.17s/it]  1%|▏         | 81/6023 [1:10:08<148:06:39, 89.73s/it]   1%|▏         | 82/6023 [1:11:46<151:59:50, 92.10s/it]  1%|▏         | 83/6023 [1:12:45<135:44:24, 82.27s/it]  1%|▏         | 84/6023 [1:14:23<143:27:55, 86.96s/it]  1%|▏         | 85/6023 [1:15:33<135:10:42, 81.95s/it]  1%|▏         | 86/6023 [1:17:21<147:49:23, 89.64s/it]  1%|▏         | 87/6023 [1:17:50<118:04:57, 71.61s/it]  1%|▏         | 88/6023 [1:18:27<100:59:58, 61.26s/it]  1%|▏         | 89/6023 [1:19:27<100:04:55, 60.72s/it]  1%|▏         | 90/6023 [1:20:04<88:15:38, 53.55s/it]   2%|▏         | 91/6023 [1:21:22<100:20:05, 60.89s/it]  2%|▏         | 92/6023 [1:22:30<103:50:59, 63.03s/it]  2%|▏         | 93/6023 [1:23:06<90:34:04, 54.98s/it]   2%|▏         | 94/6023 [1:24:08<93:50:12, 56.98s/it]  2%|▏         | 95/6023 [1:25:54<118:10:43, 71.77s/it]  2%|▏         | 96/6023 [1:27:46<138:02:59, 83.85s/it]  2%|▏         | 97/6023 [1:28:27<116:59:46, 71.07s/it]  2%|▏         | 98/6023 [1:29:15<105:22:55, 64.03s/it]  2%|▏         | 99/6023 [1:30:43<117:28:38, 71.39s/it]  2%|▏         | 100/6023 [1:32:29<134:16:00, 81.61s/it]  2%|▏         | 101/6023 [1:33:04<111:10:36, 67.58s/it]  2%|▏         | 102/6023 [1:33:39<95:18:33, 57.95s/it]   2%|▏         | 103/6023 [1:34:54<103:25:15, 62.89s/it]  2%|▏         | 104/6023 [1:36:36<123:01:49, 74.83s/it]  2%|▏         | 105/6023 [1:38:32<143:11:20, 87.10s/it]  2%|▏         | 106/6023 [1:40:02<144:50:05, 88.12s/it]  2%|▏         | 107/6023 [1:41:44<151:30:49, 92.20s/it]  2%|▏         | 108/6023 [1:42:17<122:22:24, 74.48s/it]  2%|▏         | 109/6023 [1:42:59<106:18:19, 64.71s/it]  2%|▏         | 110/6023 [1:44:48<127:55:59, 77.89s/it]  2%|▏         | 111/6023 [1:45:50<120:15:20, 73.23s/it]  2%|▏         | 112/6023 [1:47:27<131:55:20, 80.35s/it]  2%|▏         | 113/6023 [1:48:14<115:35:06, 70.41s/it]  2%|▏         | 114/6023 [1:48:58<102:10:04, 62.24s/it]  2%|▏         | 115/6023 [1:49:31<87:48:30, 53.51s/it]   2%|▏         | 116/6023 [1:51:08<109:22:52, 66.66s/it]  2%|▏         | 117/6023 [1:51:42<93:14:38, 56.84s/it]   2%|▏         | 118/6023 [1:52:14<80:52:37, 49.31s/it]  2%|▏         | 119/6023 [1:52:48<73:34:02, 44.86s/it]  2%|▏         | 120/6023 [1:54:07<90:23:25, 55.13s/it]  2%|▏         | 121/6023 [1:55:31<104:41:29, 63.86s/it]  2%|▏         | 122/6023 [1:57:06<119:41:41, 73.02s/it]  2%|▏         | 123/6023 [1:57:38<99:41:24, 60.83s/it]   2%|▏         | 124/6023 [1:58:05<82:54:05, 50.59s/it]  2%|▏         | 125/6023 [1:59:08<88:57:45, 54.30s/it]  2%|▏         | 126/6023 [2:00:08<91:38:21, 55.94s/it]  2%|▏         | 127/6023 [2:00:47<83:37:58, 51.06s/it]  2%|▏         | 128/6023 [2:01:43<85:58:41, 52.51s/it]  2%|▏         | 129/6023 [2:02:09<72:55:31, 44.54s/it]  2%|▏         | 130/6023 [2:03:40<95:30:17, 58.34s/it]  2%|▏         | 131/6023 [2:05:08<110:13:16, 67.34s/it]/root/.cache/huggingface/modules/transformers_modules/internlm/internlm-xcomposer-7b/e966f76c4294e825d97553260be065eca6a10c22/modeling_InternLM_XComposer.py:159: ResourceWarning: unclosed file <_io.BufferedReader name='/data/sy/C4MMD/data/image/Chinese/Image- (605).jpg'>
  image = Image.open(image).convert("RGB")
  2%|▏         | 132/6023 [2:05:41<93:31:34, 57.15s/it]   2%|▏         | 133/6023 [2:06:10<79:37:12, 48.66s/it]  2%|▏         | 134/6023 [2:07:01<80:46:04, 49.37s/it]/root/.cache/huggingface/modules/transformers_modules/internlm/internlm-xcomposer-7b/e966f76c4294e825d97553260be065eca6a10c22/modeling_InternLM_XComposer.py:159: ResourceWarning: unclosed file <_io.BufferedReader name='/data/sy/C4MMD/data/image/English/image_ (3057).jpg'>
  image = Image.open(image).convert("RGB")
  2%|▏         | 135/6023 [2:07:34<72:37:15, 44.40s/it]  2%|▏         | 136/6023 [2:08:03<64:47:25, 39.62s/it]  2%|▏         | 137/6023 [2:08:45<65:52:53, 40.29s/it]  2%|▏         | 138/6023 [2:09:34<70:14:37, 42.97s/it]  2%|▏         | 139/6023 [2:10:04<63:59:03, 39.15s/it]  2%|▏         | 140/6023 [2:10:46<65:30:41, 40.09s/it]  2%|▏         | 141/6023 [2:12:02<83:12:32, 50.93s/it]  2%|▏         | 142/6023 [2:14:08<119:33:23, 73.19s/it]  2%|▏         | 143/6023 [2:14:37<98:04:38, 60.05s/it]   2%|▏         | 144/6023 [2:16:12<114:57:25, 70.39s/it]  2%|▏         | 145/6023 [2:16:37<92:45:31, 56.81s/it]   2%|▏         | 146/6023 [2:17:15<83:57:36, 51.43s/it]  2%|▏         | 147/6023 [2:17:51<76:14:38, 46.71s/it]  2%|▏         | 148/6023 [2:18:58<85:57:47, 52.68s/it]